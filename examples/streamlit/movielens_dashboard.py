import os
import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta

OMDB_API_KEY = os.getenv("OMDB_API_KEY")

# URLs for MovieLens 100K dataset
DATASET_URL = "http://files.grouplens.org/datasets/movielens/ml-100k/"
RATINGS_FILE = DATASET_URL + "u.data"
ITEMS_FILE = DATASET_URL + "u.item"

# Load ratings and item data
@st.cache_data
def load_movielens_100k():
    col_rat = ['user_id', 'movie_id', 'rating', 'unix_timestamp']
    ratings_df = pd.read_csv(RATINGS_FILE, sep='\t', names=col_rat)

    col_items = [
        'movie_id', 'movie_title', 'release_date', 'video_release_date', 
        'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 
        'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 
        'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 
        'Thriller', 'War', 'Western'
    ]
    items_df = pd.read_csv(ITEMS_FILE, sep='|', names=col_items, encoding='latin-1')

    # Convert unix timestamps to datetime
    ratings_df['timestamp'] = pd.to_datetime(ratings_df['unix_timestamp'], unit='s')

    # Merge ratings and item data on movie_id
    merged_df = pd.merge(ratings_df, items_df[['movie_id', 'movie_title']], on='movie_id', how='left')

    return ratings_df, items_df, merged_df

@st.cache_data
def load_movie_posters():
    # see https://github.com/babu-thomas/movielens-posters
    poster_url = "https://raw.githubusercontent.com/babu-thomas/movielens-posters/refs/heads/master/movie_poster.csv"
    poster_df = pd.read_csv(poster_url, header=None, names=['movie_id', 'url'])
    
    # Create a dictionary to store movie_id as key and poster_url as value
    poster_dict = {}
    for _, row in poster_df.iterrows():
        poster_dict[row['movie_id']] = row['url']
    return poster_dict

def fetch_movie_details(title):
    def extract_title_year(movie_str):
        # Use regex to find the title and year
        import re
        match = re.match(r'^(.*)\s\((\d{4})\)$', movie_str)
        if match:
            title = match.group(1).strip()
            year = match.group(2)
            return title, year
        return title, None

    title, year = extract_title_year(title)
    import urllib.parse
    title = urllib.parse.quote_plus(title)
    if year:
        url = f"http://www.omdbapi.com/?t={title}&y={year}&apikey={OMDB_API_KEY}"
    else:
        url = f"http://www.omdbapi.com/?t={title}&apikey={OMDB_API_KEY}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        if data.get("Response") == "True":
            return data.get("Poster"), data.get("Plot")
        else:
            # OMDb returns a reason in 'Error' field if 'Response' is 'False'
            error_message = data.get("Error", "Unknown error")
            print(f"Error from OMDb API: {error_message}")
            return None, "No description available."
    else:
        # Handle HTTP errors
        print(f"HTTP Error: {response.status_code} - {response.reason}")
        return None, "No description available."

# Recommend movies for a given user
def recommend(user_id, merged_df, feedback, top_n=5, cutoff_days=180):
    recent_date = datetime.now() - timedelta(days=cutoff_days)
    recent_data = merged_df[merged_df["timestamp"] >= recent_date]

    # Exclude movies the user has already seen
    seen_movies = recent_data[recent_data["user_id"] == user_id]["movie_id"].unique()
    recommendations = merged_df[~merged_df["movie_id"].isin(seen_movies)].drop_duplicates("movie_id")

    # Randomly select recommendations for simplicity
    return recommendations.sample(n=top_n)

# Streamlit UI
st.title("MovieLens 100K Recommender System")
st.sidebar.header("User Input")

# Load data
ratings_df, items_df, merged_df = load_movielens_100k()

# Load movie poster data from the CSV file
poster_dict = load_movie_posters()

# User input and recommendation configuration
user_id = st.sidebar.number_input("Enter User ID", min_value=1, value=1)
top_n = st.sidebar.slider("Number of Recommendations", min_value=1, max_value=10, value=5)
cutoff_days = st.sidebar.slider("Recent Interactions (days)", min_value=30, max_value=365, value=180)

if "feedback" not in st.session_state:
    st.session_state.feedback = {"liked": [], "disliked": []}

if st.button("Get Recommendations"):
    recommendations = recommend(user_id, merged_df, st.session_state.feedback, top_n, cutoff_days)

    st.write(f"Top {top_n} recommendations for User {user_id}:")

    for _, row in recommendations.iterrows():
        title = row["movie_title"]
        movie_id = row["movie_id"]

        poster, plot = fetch_movie_details(title)
        if poster is None:
            poster = poster_dict.get(movie_id)

        st.write(f"**{title}**")
        col1, col2 = st.columns([1, 3])

        with col1:
            if poster:
                st.image(poster, width=100)
            else:
                st.write("No image available.")

        with col2:
            st.write(plot)

        liked = st.checkbox(f"üëç Like {title}", key=f"like_{row['movie_id']}")
        disliked = st.checkbox(f"üëé Dislike {title}", key=f"dislike_{row['movie_id']}")

        if liked:
            st.session_state.feedback["liked"].append(title)
        elif disliked:
            st.session_state.feedback["disliked"].append(title)

    if st.session_state.feedback:
        st.write("Updating recommendations based on your feedback...")
        new_recommendations = recommend(user_id, merged_df, st.session_state.feedback, top_n, cutoff_days)
        st.write("Updated Recommendations:")
        for _, row in new_recommendations.iterrows():
            st.write(f"- {row['movie_title']}")

# Display raw data (optional)
if st.sidebar.checkbox("Show Raw Data"):
    st.write("Ratings Data", ratings_df.head())
    st.write("Items Data", items_df.head())
